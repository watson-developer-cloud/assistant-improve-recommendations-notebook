{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Watson Assistant Performance \n",
    "### IBM Cloud Pak for Data version\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/watson-developer-cloud/assistant-improve-recommendations-notebook/master/notebook/imgs/measure_process.png\" alt=\"Measure Process\" width=\"600\"/>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to setup automated metrics that help you measure, monitor, and understand the behavior of your Watson Assistant system. As described in <a href=\"https://github.com/watson-developer-cloud/assistant-improve-recommendations-notebook/raw/master/notebook/IBM%20Watson%20Assistant%20Continuous%20Improvement%20Best%20Practices.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Assistant Continuous Improvement Best Practices</a>, this is the first step of your continuous improvement process. The goal of this step is to understand where your assistant is doing well vs where it isn’t and to potentially focus your improvement effort to one of the problem areas identified. We define two measures to achieve this goal: **Coverage** and **Effectiveness**.\n",
    "\n",
    "- **Coverage** is the portion of total user messages your assistant is attempting to respond to.\n",
    "\n",
    "- **Effectiveness** refers to how well your assistant is handling the conversations it is attempting to respond to.\n",
    "\n",
    "The pre-requisite for running this notebook is Watson Assistant (formerly Watson Conversation). This notebook assumes familiarity with Watson Assistant and concepts such as skills, workspaces, intents and training examples. \n",
    "\n",
    "### Programming language and environment\n",
    "Some familiarity with Python is recommended. This notebook runs on Python 3.7+ environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Configuration and setup](#setup)<br>\n",
    "    1.1 [Apply global CSS styles](#setup1)<br>\n",
    "    1.2 [Install Assistant Improve Toolkit](#python)<br>\n",
    "    1.3 [Import functions used in the notebook](#function)<br>\n",
    "2. [Load and format data](#load)<br>\n",
    "    2.1 [Option one: from a Watson Assistant instance](#load_remote)<br>\n",
    "    2.2 [Option two: from JSON files](#load_local)<br>\n",
    "    2.3 [Format the log data](#format_data)<br>\n",
    "3. [Define coverage and effectiveness metrics](#set_metrics)<br>\n",
    "    3.1 [Customize coverage](#set_coverage)<br>\n",
    "    3.2 [Customize effectiveness](#set_effectiveness)<br>\n",
    "4. [Calculate overall coverage and effectiveness](#overall)<br>\n",
    "    4.1 [Calculate overall metrics](#overall1)<br>\n",
    "    4.2 [Display overall results](#overall2)<br>\n",
    "5. [Analyze coverage](#msg_analysis)<br>\n",
    "    5.1 [Display overall coverage](#msg_analysis1)<br>\n",
    "    5.2 [Calculate coverage over time](#msg_analysis2)<br>\n",
    "6. [Analyze effectiveness](#conv_analysis)<br>\n",
    "    6.1 [Generate excel file and upload to our project](#conv_analysis1)<br>\n",
    "    6.2 [Plot breakdown by effectiveness graph](#conv_analysis2)<br>\n",
    "7. [Root cause analysis of non coverage](#root_cause)<br>\n",
    "8. [Abandoned and resolved intent analysis](#abandoned_resolved_intents)<br>\n",
    "    8.1 [Count of all started intents](#started_intents)<br>\n",
    "    8.2 [Analyze resolved intents](#resolved_intents)<br>\n",
    "    8.3 [Analyze abandoned intents](#abandoned_intents)<br>\n",
    "9. [Summary and next steps](#summary)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Configuration and Setup\n",
    "\n",
    "In this section, we install and import required libraries and functions and add project access token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"setup1\"></a> 1.1 Import and apply global CSS styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and apply global CSS styles\n",
    "from IPython.display import HTML\n",
    "!curl -O https://raw.githubusercontent.com/watson-developer-cloud/assistant-improve-recommendations-notebook/master/src/main/css/custom.css\n",
    "HTML(open('custom.css', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"python\"></a> 1.2 Install Assistant Improve Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install --user --upgrade \"assistant-improve-toolkit\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"function\"></a> 1.3 Import functions used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from pandas import json_normalize\n",
    "from ibm_watson import AssistantV1, AssistantV2\n",
    "from IPython.display import display\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "\n",
    "# Import the visualization related functions\n",
    "from assistant_improve_toolkit.visualize_func import make_pie, coverage_barh, width_bar, show_coverage_over_time\n",
    "# Import Cloud Object Storage related functions   \n",
    "from assistant_improve_toolkit.cos_op import generate_link, generate_excel_measure, export_result_excel\n",
    "# Import Watson Assistant related functions\n",
    "from assistant_improve_toolkit.watson_assistant_func import get_logs, get_assistant_definition, load_logs_from_file\n",
    "# Import Dataframe computation related functions\n",
    "from assistant_improve_toolkit.computation_func import get_effective_df, get_coverage_df, chk_is_valid_node, format_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"load\"></a> 2. Load and format data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"load_remote\"></a> 2.1 Option one: from a Watson Assistant instance\n",
    "\n",
    "#### 2.1.1 Add Watson Assistant configuration\n",
    "\n",
    "The notebook uses `CloudPakForDataAuthenticator` to authenticate the APIs.\n",
    "\n",
    "- Replace `username` and `password` with your Cloud Pak for Data credentials\n",
    "- `base_url` is the base URL of your instance. It is in the format of `https://{cpd_cluster_host}{:port}/icp4d-api`\n",
    "- The string to set for version is a date in the format version=YYYY-MM-DD. The version date string determines which version of the Watson Assistant v1/v2 API will be called. For more information about version, see [Versioning](https://cloud.ibm.com/apidocs/assistant-data-v1?code=python#versioning)\n",
    "- The string to pass into `assistant.set_service_url` is the service URL of your Watson Assistant. The URL follows this pattern: `https://{cpd_cluster_host}{:port}/assistant/{release}/instances/{instance_id}/api`. To find this  URL, view the details for the service instance from the Cloud Pak for Data web client. For more information, see [Service Endpoint](https://cloud.ibm.com/apidocs/assistant-data-v1?code=python#service-endpoint)\n",
    "\n",
    "The notebook requires initializing both v1 API instance `sdk_v1_object`  and v2 API instance `sdk_v2_object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide credentials to connect to assistant\n",
    "# Set disable_ssl_verification=True for self-signed certificate\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "    username='username',\n",
    "    password='password',\n",
    "    url='base_url',\n",
    "    disable_ssl_verification=False\n",
    ")\n",
    "\n",
    "# Initialize v1 API instance\n",
    "sdk_v1_object = AssistantV1(version='2020-04-01', authenticator = authenticator)\n",
    "sdk_v1_object.set_service_url('service_url')\n",
    "\n",
    "# Initialize v2 API instance\n",
    "sdk_v2_object = AssistantV2(version='2020-09-24', authenticator = authenticator)\n",
    "sdk_v2_object.set_service_url('service_url')\n",
    "\n",
    "# Set set_disable_ssl_verification to True for self-signed certificate\n",
    "# sdk_v1_object.set_disable_ssl_verification(True)\n",
    "# sdk_v2_object.set_disable_ssl_verification(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the information of your assistant. To load the skill of an assistant in the next section, you need to provide either Workspace ID or Skill ID. To locate your assistant ID, open the assistant settings and click __API Details__. To location your workspace ID or skill ID, go to the Skills page and select __View API Details__ from the menu of a skill tile. If you are using versioning in Watson Assistant, this ID represents the Development version of your skill definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_information = {'workspace_id' : '',\n",
    "                         'skill_id' : '',\n",
    "                         'assistant_id' : ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Fetch and load the definition of your assistant \n",
    "\n",
    "Fetch assistant definition and load into a dataframe. The notebook uses v1 API instance `sdk_v1_object` to access skill definition. Note that assistant definition will be saved into a cached file and loaded from the file. Set `overwrite` to True to refresh the cached file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assistant = get_assistant_definition(sdk_v1_object, assistant_information, overwrite=False)\n",
    "\n",
    "if df_assistant is not None:\n",
    "    # Get all intents\n",
    "    assistant_intents = [intent['intent'] for intent in df_assistant['intents'].values[0]] \n",
    "    # Get all dialog nodes\n",
    "    assistant_nodes = pd.DataFrame(df_assistant['dialog_nodes'].values[0])\n",
    "    assistant_loaded = True\n",
    "else:\n",
    "    assistant_loaded = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Fetch and load logs\n",
    "\n",
    "Fetch user generated logs. By default, the notebook fetches message logs using v2 APIs. Set `version=1` to query message logs generated by both v1 and v2 APIs. \n",
    "\n",
    "You can apply filters while fetching logs, e.g.,\n",
    "- removing empty input: `meta.summary.input_text_length_i>0`\n",
    "- fetching logs generated after a timestamp: `response_timestamp>=2018-09-18`\n",
    "\n",
    "See more examples in [Logs notebook](https://github.com/watson-developer-cloud/assistant-improve-recommendations-notebook/blob/master/notebook/Logs%20Notebook.ipynb).\n",
    "\n",
    "Note that logs will be saved into a cached file and loaded from the file. Set `overwrite` to True to refresh the cached file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output filename\n",
    "filename = 'logs'\n",
    "# Create file name\n",
    "if assistant_information['workspace_id'] is not None and len(assistant_information['workspace_id']) > 0:\n",
    "    filename += '_workspace_' + assistant_information['workspace_id']\n",
    "if assistant_information['assistant_id'] is not None and len(assistant_information['assistant_id']) > 0:\n",
    "    filename += '_assistant_' + assistant_information['assistant_id']\n",
    "if assistant_information['skill_id'] is not None and len(assistant_information['skill_id']) > 0:\n",
    "    filename += '_skill_' +  assistant_information['skill_id']\n",
    "# Remove all special characters from file name\n",
    "filename = re.sub(r'[^a-zA-Z0-9_\\- .]', '', filename) + '.json'\n",
    "\n",
    "# Filter to be applied while fetching logs\n",
    "filters = ['language::en',\n",
    "           'meta.summary.input_text_length_i>0']\n",
    "\n",
    "# Fetch the logs, set `overwrite` to True to reload logs, set version=2 to use v2 log apis\n",
    "log_raw_data = get_logs(sdk_v1_object=sdk_v1_object,\n",
    "                        sdk_v2_object=sdk_v2_object,\n",
    "                        assistant_info=assistant_information,\n",
    "                        num_logs=20000,\n",
    "                        filename=filename,\n",
    "                        filters=filters,\n",
    "                        overwrite=False,\n",
    "                        version=2)\n",
    "\n",
    "df_logs = pd.DataFrame(log_raw_data)\n",
    "\n",
    "if log_raw_data is not None:\n",
    "    # Mark that logs have been loaded\n",
    "    logs_loaded = True\n",
    "else:\n",
    "    logs_loaded = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"load_local\"></a> 2.2 Option two: from JSON files\n",
    "\n",
    "#### 2.2.1 Load a workspace JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not assistant_loaded:\n",
    "    \n",
    "    # The following code is for using demo workspace\n",
    "    import requests\n",
    "    print('Loading workspace data from Watson developer cloud Github repo ... ', end='')\n",
    "    workspace_data = requests.get(\"https://raw.githubusercontent.com/watson-developer-cloud/assistant-improve-recommendations-notebook/master/notebook/data/workspace.json\").text    \n",
    "    df_assistant = json_normalize(json.loads(workspace_data))\n",
    "    \n",
    "#    # Specify assistant definition JSON file\n",
    "#     assistant_definition_file = 'SPECIFY_FILE_NAME'\n",
    "#     print('Loading assistant definition from {}'.format(assistant_definition_file))\n",
    "\n",
    "#    # Store assistant definition in a dataframe\n",
    "#     df_assistant = json_normalize(json.load(open(assistant_definition_file)))\n",
    "\n",
    "    # Get all intents\n",
    "    assistant_intents = [intent['intent'] for intent in df_assistant['intents'].values[0]] \n",
    "\n",
    "    # Get all dialog nodes\n",
    "    assistant_nodes = pd.DataFrame(df_assistant['dialog_nodes'].values[0])\n",
    "    print('completed!')\n",
    "else:\n",
    "    print('Assistant definition has been loaded in Section 2.1.2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Load a log JSON file\n",
    "\n",
    "Another option is to load an existing log JSON file.  Log JSON files can be produced by using [Logs notebook](https://github.com/watson-developer-cloud/assistant-improve-recommendations-notebook/blob/master/notebook/Logs%20Notebook.ipynb), or [`fetch_logs`](https://github.com/watson-developer-cloud/assistant-improve-recommendations-notebook/blob/master/src/main/python/fetch_logs.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logs_loaded:\n",
    "    # The following code is for using demo logs\n",
    "    import requests\n",
    "    print('Loading demo log data from Watson developer cloud Github repo ... ', end='')\n",
    "    log_raw_data = requests.get(\"https://raw.githubusercontent.com/watson-developer-cloud/assistant-improve-recommendations-notebook/master/notebook/data/sample_logs.json\").text\n",
    "    print('completed!')\n",
    "    logs = json.loads(log_raw_data)\n",
    "\n",
    "    # The following code is for loading your log file\n",
    "    # Specify a log JSON file\n",
    "    # logs = load_logs_from_file(filename='logs.json')\n",
    "\n",
    "    df_logs = pd.DataFrame(logs)\n",
    "else:\n",
    "    print('Logs have been loaded in Section 2.1.3.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"format_data\"></a> 2.3 Format the log data\n",
    "\n",
    "The logs returned from `logs` API are stored in a nested structure. In this step, we expand the nested structure and extract the fields used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the logs data from the workspace\n",
    "df_formated = format_data(df_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"set_metrics\"></a>\n",
    "## 3. Define effectiveness and coverage metrics\n",
    "As described in Watson Assistant Continuous Improvement Best Practices, **Effectiveness** and **Coverage** are the two measures that provide a reliable understanding of your assistant’s overall performance. Both of the two measures are customizable based on your preferences. In this section, we provide a guideline for setting each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"set_coverage\"></a> 3.1 Customize coverage\n",
    "\n",
    "Coverage measures your Watson Assistant system at the utterance level. You may include automated metrics that help identify utterences that your service is not answering. Example metrics include: \n",
    "\n",
    "- Confidence threshold\n",
    "- Dialog information\n",
    "\n",
    "For Confidence threshold, you can set a threshold to include utterances with confidence values below this threshold. For more information regarding Confidence, see [Absolute scoring](https://cloud.ibm.com/docs/services/assistant?topic=assistant-intents#intents-absolute-scoring).\n",
    "\n",
    "For Dialog information, you can specify what the notebook should look for in your logs to determine that a message is not covered by your assistant.\n",
    "\n",
    "- Use the node_ids list to include the identifiers of any dialog nodes you've used to model that a message is out of scope.  \n",
    "- Similarly, use the node_names list to include any dialog nodes.\n",
    "- Use node_conditions for dialog conditions that indicate a message is out of scope.\n",
    "    \n",
    "Note that these lists are treated as \"OR\" conditions - any occurrence of any of them will signify that a message is not covered. \n",
    "\n",
    "__Where to find node id, node name, and node condition__?\n",
    "\n",
    "You can find the values of these variables from your assistant definition JSON file based on following mappings.\n",
    "\n",
    "- node id: `dialog_node`\n",
    "- node name: `title`\n",
    "- node condition: `conditions`\n",
    "\n",
    "You can also find node name, and node condition in your dialog editor. For more information, see [Dialog Nodes](https://cloud.ibm.com/docs/services/assistant?topic=assistant-dialog-overview#dialog-overview-nodes).\n",
    "\n",
    "Below we provide example code for identifying coverage based on confidence and dialog node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the confidence threhold you want to look for in the logs\n",
    "confidence_threshold = .20\n",
    "\n",
    "# Add coverage node ids, if any, to list\n",
    "node_ids = ['node_1_1467910920863', 'node_1_1467919680248']\n",
    "\n",
    "# Add coverage node names, if any, to list\n",
    "node_names = []\n",
    "\n",
    "# Add coverage node conditions, if any, to list\n",
    "node_conditions = ['#out_of_scope || #off_topic', 'anything_else']\n",
    "\n",
    "# Check if the dialog nodes are present in assistant definition\n",
    "df_coverage_nodes = chk_is_valid_node(node_ids, node_names, node_conditions, assistant_nodes)\n",
    "df_coverage_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"set_effectiveness\"></a> 3.2 Customize effectiveness\n",
    "\n",
    "Effectiveness measures your Watson Assistant system at the conversation level. You may include automated metrics that help identify problematic conversations. Example metrics include:\n",
    "\n",
    "- Escalations to live agent: conversations escalated to a human agent for quality reasons.\n",
    "- Poor NPS: conversations that received a poor NPS (Net Promoter Score), or other explicit user feedback.\n",
    "- Task not completed: conversations failed to complete the task the user was attempting.\n",
    "- Implicit feedback: conversations containing implicit feedback that suggests failure, such as links provided not being clicked. \n",
    "\n",
    "Below we provide example code for identifying escalation based on intents and dialog information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"set_escalation_intent\"></a> 3.2.1 Specify intents to identify escalations\n",
    "If you have specific intents that point to escalation or any other effectiveness measure, specify those in `chk_effective_intents` lists below. <br>\n",
    "**Note:** If you don't have specific intents to capture effectiveness, leave chk_effective_intents list empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your escalation intents to the list\n",
    "chk_effective_intents=['connect_to_agent']\n",
    "\n",
    "# Store the intents in a dataframe\n",
    "df_chk_effective_intents = pd.DataFrame(chk_effective_intents, columns = ['Intent'])\n",
    "\n",
    "# Add a 'valid' flag to the dataframe\n",
    "df_chk_effective_intents['Valid']= True\n",
    "\n",
    "# Add count column for selected intents\n",
    "df_chk_effective_intents['Count']= 0\n",
    "\n",
    "# Checking the validity of the specified intents. Look out for the `valid` column in the table displayed below.\n",
    "for intent in chk_effective_intents:\n",
    "    # Check if intent is present in assistant definition\n",
    "    if intent not in assistant_intents:\n",
    "        # If not present, mark it as 'not valid'\n",
    "        df_chk_effective_intents.loc[df_chk_effective_intents['Intent']==intent,['Valid']] = False\n",
    "        # Remove intent from the chk_effective_intents list \n",
    "        chk_effective_intents.remove(intent)\n",
    "    else:\n",
    "        # Calculate number of times each intent is hit\n",
    "        count = df_formated.loc[df_formated['response.top_intent_intent']==intent]['log_id'].nunique()\n",
    "        df_chk_effective_intents.loc[df_chk_effective_intents['Intent']==intent,['Count']] = count\n",
    "# Display intents and validity\n",
    "df_chk_effective_intents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id=\"set_escalation_dialog\"></a> 3.2.2 Specify  dialog nodes to identify escalations\n",
    "If you have specific dialog nodes that point to escalation or any other effectiveness measure, you can automated capture them based on three variables: node id, node name, and node condition.\n",
    "\n",
    "- Use the node_ids list to include the identifiers of any dialog nodes you've used to model that a message indicates an escalation.  \n",
    "- Similarly, use the node_names list to include dialog nodes.\n",
    "- Use node_conditions for dialog conditions that indicate a message is out of scope.\n",
    "\n",
    "Note that these lists are treated as \"OR\" conditions - any occurrence of any of them will signify that a message is not covered. \n",
    "\n",
    "__Where to find node id, node name, and node condition__?\n",
    "\n",
    "You can find the values of these variables from your assistant definition JSON file based on following mappings.\n",
    "\n",
    "- node id: `dialog_node`\n",
    "- node name: `title`\n",
    "- node condition: `conditions`\n",
    "\n",
    "You can also find node name, and node condition in your dialog editor. For more information, see [Dialog Nodes](https://cloud.ibm.com/docs/services/assistant?topic=assistant-dialog-overview#dialog-overview-nodes).\n",
    "\n",
    "**Note:** If your assistant does not incorporate escalations and you do not have any other automated conversation-level quality metrics to identify problematic conversations (e.g., poor NPS, task not completed), you can simply track coverage and average confidence over a recent sample of your entire production logs. Leave an empty list for node_ids, node_names and node_conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add effectiveness node ids, if any, to list\n",
    "node_ids = []\n",
    "\n",
    "# Add effectiveness node names, if any, to list\n",
    "node_names = ['not_trained']\n",
    "\n",
    "# Add effectiveness node conditions, if any, to list\n",
    "node_conditions = ['#connect_to_agent', '#answer_not_helpful']\n",
    "\n",
    "# If your assistant does not incorporate escalations and you do not have any other automated conversation-level quality metrics, uncomment lines below \n",
    "# node_ids = [] \n",
    "# node_names = [] \n",
    "# node_conditions = [] \n",
    "\n",
    "# Check if the dialog nodes are present in assistant definition\n",
    "df_chk_effective_nodes = chk_is_valid_node(node_ids, node_names, node_conditions, assistant_nodes)\n",
    "df_chk_effective_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate overall coverage and effectiveness<a id=\"overall\"></a>\n",
    "The combination of effectiveness and coverage is very powerful for diagnostics.\n",
    "If your effectiveness and coverage metrics are high, it means that your assistant is responding to most inquiries and responding well. If either effectiveness or coverage are low, the metrics provide you with the information you need to start improving your assistant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1 Calculate overall metrics<a id=\"overall1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formated_copy = df_formated.copy(deep = True)\n",
    "\n",
    "# Mark if a message is covered and store results in df_coverage dataframe\n",
    "df_coverage = get_coverage_df(df_formated_copy , df_coverage_nodes, confidence_threshold)\n",
    "\n",
    "# Mark if a conversation is effective and store results in df_coverage dataframe\n",
    "# Set filter_non_intent_node to True to filter out utterances whose last visited node does not contain any intents\n",
    "df_effective = get_effective_df(df_formated_copy, chk_effective_intents, df_chk_effective_nodes, filter_non_intent_node=False, assistant_nodes=assistant_nodes)\n",
    "\n",
    "# Calculate average confidence\n",
    "avg_conf = float(\"{0:.2f}\".format(df_coverage[df_coverage['Covered']==True]['response.top_intent_confidence'].mean()*100))\n",
    "\n",
    "# Calculate coverage\n",
    "coverage = float(\"{0:.2f}\".format((df_coverage['Covered'].value_counts().to_frame()['Covered'][True]/df_coverage['Covered'].value_counts().sum())*100))\n",
    "\n",
    "# Calculate effectiveness\n",
    "effective_perc = float(\"{0:.2f}\".format((df_effective.loc[df_effective['Escalated_conversation']==False]['response.context.conversation_id'].nunique()/df_effective['response.context.conversation_id'].nunique())*100))              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.2 Display overall results<a id=\"overall2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pie graphs for coverage and effectiveness\n",
    "coverage_pie = make_pie(coverage, \"Percent of total messages covered\")\n",
    "effective_pie = make_pie(effective_perc, 'Percent of non-escalated conversations')\n",
    "\n",
    "# Messages to be displayed with effectiveness and coverage\n",
    "coverage_msg = '<h2>Coverage</h2></br>A message that is not covered would either be a \\\n",
    "message your assistant responded to with some form \\\n",
    "of “I’m not trained” or that it immediately handed over \\\n",
    "to a human agent without attempting to respond'\n",
    "\n",
    "effectiveness_msg = '<h2>Effectiveness</h2></br>This notebook provides a list of metrics customers \\\n",
    "can use to assess how effective their assistant is at \\\n",
    "responding to conversation and metrics '\n",
    "\n",
    "# Display the coverage and effectiveness pie charts\n",
    "HTML('<tr><th colspan=\"4\"><div align=\"center\"><h2>Coverage and Effectiveness<hr/></h2></div></th></tr>\\\n",
    "<tr>\\\n",
    "    <td style=\"width:500px\">{c_pie}</td>\\\n",
    "    <td style=\"width:450px\"><div align=\"left\"> {c_msg} </div></td>\\\n",
    "    <td style=\"width:500px\">{e_pie}</td>\\\n",
    "    <td style=\"width:450px\"><div align=\"left\"> {e_msg}  </div></td>\\\n",
    "</tr>'\n",
    "    .format(c_pie=coverage_pie, c_msg = coverage_msg, e_pie = effective_pie, e_msg = effectiveness_msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see our assistant's coverage and effectiveness. We will have to take a deeper look at both of these metrics to understand the nuances and decide where we should focus next. \n",
    "\n",
    "Note that the distinction between a user message and a conversation. A conversation in Watson Assistant represents a session of one or more messages from a user and the associated responses returned to the user from the assistant. A conversation includes a Conversation id for the purposes of grouping a sequence of messages and responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"msg_analysis\"></a>\n",
    "## 5.  Analyze coverage\n",
    "\n",
    "Now, we take a deeper look at the Coverage of your Assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.1 Display overall coverage<a id=\"msg_analysis1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of conversations in the log\n",
    "convs = df_coverage['response.context.conversation_id'].nunique()\n",
    "\n",
    "# Compute the number of messages in the log\n",
    "msgs = df_coverage['response.context.conversation_id'].size\n",
    "\n",
    "#Display the results\n",
    "print('Overall messages\\n', \"=\" * len('Overall messages'), '\\nTotal Conversations: ', convs, '\\nTotal Messages: ', msgs, '\\n\\n', sep = '')\n",
    "\n",
    "#Display the coverage bar chart\n",
    "display(coverage_barh(coverage, avg_conf, 'Coverage & Average confidence', False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.2 Calculate coverage over time<a id=\"msg_analysis2\"></a>\n",
    "\n",
    "Compare the coverage over time with any major updates to your assistant, to see if the changes affected the performance. Use the interval parameter to set a time interval.  You can choose from:  {\"minute\", \"5-minute\", \"15-minute\", \"30-minute\", \"hour\", \"day\", \"week\", \"month\"}. Move your cursor over the bars to check the coverage value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_coverage_over_time(df_coverage, interval='day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conv_analysis\"></a>\n",
    "## 6. Analyze effectiveness\n",
    "\n",
    "Here, we take a deeper look at the effectiveness of your assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the escalated conversations\n",
    "df_effective_true = df_effective.loc[df_effective['Escalated_conversation']==True]\n",
    "\n",
    "# Get the non-escalated conversations\n",
    "df_not_effective = df_effective.loc[df_effective['Escalated_conversation']==False]\n",
    "\n",
    "# Calculate percentage of escalated conversations\n",
    "ef_escalated = float(\"{0:.2f}\".format(100-effective_perc))\n",
    "\n",
    "# Calculate coverage and non-coverage in escalated conversations\n",
    "if len(df_effective_true) > 0:\n",
    "    escalated_covered = float(\"{0:.2f}\".format((df_effective_true['Covered'].value_counts().to_frame()['Covered'][True]/df_effective_true['Covered'].value_counts().sum())*100))\n",
    "    escalated_not_covered = float(\"{0:.2f}\".format(100- escalated_covered))\n",
    "else:\n",
    "    escalated_covered = 0\n",
    "    escalated_not_covered = 0\n",
    "\n",
    "# Calculate coverage and non-coverage in non-escalated conversations\n",
    "if len(df_not_effective) > 0:\n",
    "    not_escalated_covered = float(\"{0:.2f}\".format((df_not_effective['Covered'].value_counts().to_frame()['Covered'][True]/df_not_effective['Covered'].value_counts().sum())*100))\n",
    "    not_escalated_not_covered = float(\"{0:.2f}\".format(100 - not_escalated_covered))\n",
    "else:\n",
    "    not_escalated_covered = 0\n",
    "    not_escalated_not_covered = 0\n",
    "\n",
    "# Calculate average confidence of escalated conversations\n",
    "if len(df_effective_true) > 0:\n",
    "    esc_avg_conf = float(\"{0:.2f}\".format(df_effective_true[df_effective_true['Covered']==True]['response.top_intent_confidence'].mean()*100))\n",
    "else:\n",
    "    esc_avg_conf = 0\n",
    "    \n",
    "# Calculate average confidence of non-escalated conversations\n",
    "if len(df_not_effective) > 0:\n",
    "    not_esc_avg_conf = float(\"{0:.2f}\".format(df_not_effective[df_not_effective['Covered']==True]['response.top_intent_confidence'].mean()*100))\n",
    "else:\n",
    "    not_esc_avg_conf = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.1 Generate excel file and save to your project<a id=\"conv_analysis1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sampling size for conversations, set to -1 to disable sampling\n",
    "SAMPLE_SIZE = 100\n",
    "export_result_excel(df_effective, sample_size=SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.2 Plot breakdown by effectiveness graph<a id=\"conv_analysis2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the links to the excels\n",
    "all_html_link = '<a href={} target=\"_blank\">All.xlsx</a>'.format('All.xlsx')\n",
    "escalated_html_link = '<a href={} target=\"_blank\">Escalated_sample.xlsx</a>'.format('Escalated_sample.xlsx')\n",
    "not_escalated_html_link = '<a href={} target=\"_blank\">NotEscalated_sample.xlsx</a>'.format('NotEscalated_sample.xlsx')\n",
    "\n",
    "# Embed the links in HTML table format\n",
    "link_html = '<tr><th colspan=\"4\"><div align=\"left\"><a id=\"file_list\"></a>View the lists here: {}&nbsp;&nbsp;&nbsp;{}&nbsp;&nbsp;&nbsp;{}</div></th></tr>'.format(all_html_link, escalated_html_link, not_escalated_html_link)\n",
    "\n",
    "if 100-effective_perc > 0:\n",
    "    escalated_bar = coverage_barh(escalated_covered, esc_avg_conf, '', True, 15, width_bar(100-effective_perc))\n",
    "else:\n",
    "    escalated_bar = ''\n",
    "\n",
    "if effective_perc > 0: \n",
    "    non_escalated_bar = coverage_barh(not_escalated_covered, not_esc_avg_conf, '' , True , 15,width_bar(effective_perc))\n",
    "else:\n",
    "    non_escalated_bar = ''\n",
    "\n",
    "# Plot the results\n",
    "HTML('<tr><th colspan=\"4\"><div align=\"left\"><h2>Breakdown by effectiveness<hr/></h2></div></th></tr>\\\n",
    "'+ link_html + '<tr><td style= \"border-right: 1px solid black; border-bottom: 1px solid black; width : 400px\"><div align=\"left\"><strong>Effectiveness (Escalated)&nbsp;</br>\\\n",
    "<font size=\"5\">{ef_escalated}%</strong></font size></br></div></td>\\\n",
    "    <td style=\"width:1000px; height=100;\">{one}</td></tr>\\\n",
    "<tr><td style= \"border-right: 1px solid black; border-bottom: 1px solid black; width : 400px;\"><div align=\"left\"><strong>Effectiveness (Not escalated)&nbsp;</br>\\\n",
    "<font size=\"5\">{effective_perc}%</strong></font size></br></div></td>\\\n",
    "    <td style=\"width:1000px; height=100;border-bottom: 1px solid black;\">{two}</td>\\\n",
    "</tr>'.format(ef_escalated= ef_escalated,\n",
    "              one = escalated_bar, \n",
    "              effective_perc = effective_perc, \n",
    "              two = non_escalated_bar)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download all the analyzed data from `All.xlsx`. A sample of escalated and non-escalated conversations are available in `Escalated_sample.xlsx` and `NotEscalated_sample.xlsx` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"root_cause\"></a>\n",
    "## 7. Root cause analysis of non coverage\n",
    "Let us take a look at the reasons for non-coverage of messages\n",
    "\n",
    "**Note**: In order to run this analysis you’ll need to pass `input.options.debug=true` on the message requests. For more information, see [Message - Query Parameters](https://cloud.ibm.com/apidocs/assistant-data-v2#message). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the causes for non-coverage and store results in dataframe\n",
    "not_covered = pd.DataFrame(df_coverage['Not Covered cause'].value_counts().reset_index())\n",
    "# Name the columns in the dataframe\n",
    "not_covered.columns = ['Messages', 'Total']\n",
    "not_covered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"abandoned_resolved_intents\"></a>\n",
    "## 8. Abandoned and resolved intent analysis\n",
    "\n",
    "When users engage in a conversation session, an assistant identifies the intent of each message from the user. Based on the logic flow defined in a dialog tree, the assistant communicates with users and performs actions. The assistant may succeed or fail to satisfy users' intent.  One way to identify patterns of success or failure is by analyzing which intents most often lead to a dialog node associated with resolution, and which intents most often lead to users abandoning the session.  Analyzing resolved and abandoned intents can help you identify issues in your assistant to improve, such as a problematic dialog flow or imprecise intents. In this section, we demonstrate a method of conducting intent analysis using context variables.\n",
    "\n",
    "We introduce two context variables: `response_context_IntentStarted` and `response_context_IntentCompleted`.  You will need to modify your dialog skill definition (workspace) to introduce these variables in your dialog flow.  After you modify your dialog skill definition, your logs will be marked such that when users trigger a conversation with an intent, the assistant will use `response_context_IntentStarted` to record the intent. During the conversation, the assistant will use `response_context_IntentCompleted` to record if the intent is satisfied. Follow the steps below to add the context variables for an intent in your dialog skill definition.\n",
    "\n",
    "1. Open Dialog Overview page, see <a href=\"https://cloud.ibm.com/docs/services/assistant?topic=assistant-dialog-overview\" target=\"_blank\">Dialog Overview</a> for more information.\n",
    "2. Click the entry point node of the dialog node that is associated with the intent you want to analyze\n",
    "3. Open the context editor, see <a href=\"https://cloud.ibm.com/docs/services/assistant?topic=assistant-dialog-runtime#dialog-runtime-context-variables\" target=\"_blank\">Context Variables</a> for more information\n",
    "4. Add `response_context_IntentStarted` as a variable and \\[intent_name\\] as the value\n",
    "5. Follow the dialog flow to locate the satisfying node of the intent\n",
    "6. Open the context editor\n",
    "7. Add `response_context_IntentCompleted` as variable and \\[intent_name\\] as the value\n",
    "8. Repeat step 5-7 to mark all satisfying nodes of the intent if necessary\n",
    "\n",
    "Then repeat the above steps for every intent you want to analyze in this way.\n",
    "\n",
    "After completing the above steps, run the following code for intent analysis. Note that the analysis requires logs generated after the above changes. You will need to reload the updated assistant definition and logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8.1 Count of all started intents<a id=\"started_intents\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define context variables\n",
    "start_intent_variable = 'response_context_IntentStarted'\n",
    "\n",
    "if start_intent_variable in df_formated:\n",
    "    # Group dataframe by conversation_id and start_intent_variable\n",
    "    df_intent_started = df_formated.groupby(['response.context.conversation_id', start_intent_variable]).count().reset_index()\n",
    "    # Refactors data to show only columns of conversation_id and start_intent_variable\n",
    "    df_intent_started = df_intent_started[['response.context.conversation_id', start_intent_variable]]\n",
    "\n",
    "    # Count the number of conversation_ids with each start_intent_variable\n",
    "    intent_started = df_intent_started[start_intent_variable].value_counts().reset_index()\n",
    "    intent_started.columns = ['Intent', 'Count']\n",
    "    display(HTML(intent_started.to_html()))\n",
    "else:\n",
    "    print('Cannot find \\'response_context_IntentStarted\\' and \\'response_context_IntentCompleted\\' in logs. Please check step 4 and make sure updated logs are reloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8.2 Analyze resolved intents<a id=\"resolved_intents\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_intent_variable = 'response_context_IntentCompleted'\n",
    "\n",
    "if end_intent_variable in df_formated:\n",
    "\n",
    "    # Group dataframe by conversation_id and end_intent_variable\n",
    "    df_intent_completed = df_formated.groupby(['response.context.conversation_id',end_intent_variable]).count().reset_index()\n",
    "    # Refactor data to show columns of conversation_id and end_intent_variable only\n",
    "    df_intent_completed = df_intent_completed[['response.context.conversation_id',end_intent_variable]]\n",
    "    # Count the number of conversation_ids with each end_intent_variable\n",
    "    intent_completed = df_intent_completed[end_intent_variable].value_counts().reset_index()\n",
    "    intent_completed.columns = ['Intent', 'Count']\n",
    "\n",
    "    # Show counts of resolved intents\n",
    "    intent_completed_title = '\\nCount of resolved intents in all conversations\\n'\n",
    "    print(intent_completed_title, \"=\" * len(intent_completed_title),'', sep = '')\n",
    "    display(HTML(intent_completed.to_html()))\n",
    "\n",
    "    # Convert dataframe to a list\n",
    "    res_intent_list = intent_completed.values.tolist()\n",
    "    # Get list of started intents\n",
    "    all_intent = df_intent_started[start_intent_variable].value_counts().reset_index().values.tolist()\n",
    "\n",
    "    # Loop over resolved intents list. Each element contains a pair of intent and count\n",
    "    data = []\n",
    "    for pair_ab in res_intent_list:\n",
    "        # Loop over each row of started intents. Each row contains a pair of intent and count\n",
    "        for pair_all in all_intent:\n",
    "            # Check if the intent name matches in started and resolved intents\n",
    "            if pair_ab[0] == pair_all[0]:\n",
    "                # Then acccesses the count from that matched intent, and calculate percentage\n",
    "                perc = (pair_ab[1]/pair_all[1])*100\n",
    "                # Add the matched intent name and percentage to data list\n",
    "                data.append([pair_ab[0],perc])\n",
    "\n",
    "    # Create a new dataframe with data list\n",
    "    resolved_percentage = pd.DataFrame(data=data).reset_index(drop=True)\n",
    "\n",
    "    # Format the dataframe, and orders data in descending order (shows highest percentage first)\n",
    "    resolved_percentage.columns = ['Intent','Percentage']\n",
    "    resolved_percentage.sort_values(ascending=False,inplace=True, by='Percentage')\n",
    "    # Format the data in the percentage column to include '%', and 1 decimal point\n",
    "    resolved_percentage['Percentage'] = resolved_percentage['Percentage'].apply(lambda x: \"{0:.1f}%\".format(x))\n",
    "    resolved_percentage.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Show most resolved intents\n",
    "    most_resolved_intents = \"\\nMost resolved intents (%)\\n\"\n",
    "    print(most_resolved_intents, \"=\" * len(most_resolved_intents),'', sep = '')\n",
    "    display(HTML(resolved_percentage.to_html()))\n",
    "\n",
    "else:\n",
    "    print('Cannot find \\'response_context_IntentStarted\\' and \\'response_context_IntentCompleted\\' in logs. Please check step 4 and make sure updated logs are reloaded.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8.3 Analyze abandoned intents<a id=\"abandoned_intents\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_intent_variable in df_formated and end_intent_variable in df_formated:\n",
    "\n",
    "    # Create lists of started and end_intent_variable\n",
    "    intent_complete_list = df_intent_completed.values.tolist()\n",
    "    intent_started_list = df_intent_started.values.tolist()\n",
    "\n",
    "    # Looping over completed intents list. Each element contains a pair of conversation id and end_intent_variable\n",
    "    for pair in intent_complete_list:\n",
    "        # Checks if any element is found in list of started intents\n",
    "        if pair in intent_started_list:\n",
    "            # If found, remove that pair from the list of started intents\n",
    "            intent_started_list.remove(pair)\n",
    "\n",
    "    # Create a new dataframe with updated dataset. \n",
    "    # This updated dataset contains intents that have been started but not completed, thus categorised as abandoned\n",
    "    df_intent_abandoned = pd.DataFrame(data=intent_started_list)\n",
    "    if len(df_intent_abandoned) > 0:\n",
    "        # Group each pair (conversation id, intent abandoned), and show number of occurances of each abandoned intent\n",
    "        final_intent_abandoned = df_intent_abandoned[1].value_counts().reset_index()\n",
    "        final_intent_abandoned.columns = ['Intent','Count']\n",
    "\n",
    "        # Show counts of abandoned intents\n",
    "        intent_abandoned_title = '\\nCount of abandoned intents in all conversations\\n'\n",
    "        print(intent_abandoned_title, \"=\" * len(intent_abandoned_title),'', sep = '')\n",
    "        display(HTML(final_intent_abandoned.to_html()))\n",
    "\n",
    "        # Convert dataframe to a list\n",
    "        aban_intent_list = final_intent_abandoned.values.tolist()\n",
    "        # Get list of started intents\n",
    "        all_intent = df_intent_started[start_intent_variable].value_counts().reset_index().values.tolist()\n",
    "\n",
    "        # Loop over resolved intents list. Each element contains a pair of intent and count\n",
    "        data = []\n",
    "        for pair_ab in aban_intent_list:\n",
    "            # Loop over each row of started intents. Each row contains a pair of intent and count\n",
    "            for pair_all in all_intent:\n",
    "                # Check if the intent name matches in started and resolved intents\n",
    "                if pair_ab[0] == pair_all[0]:\n",
    "                    # Then acccesse the count from that matched intent, and calculate percentage\n",
    "                    perc = (pair_ab[1]/pair_all[1])*100\n",
    "                    # Add the matched intent name and percentage to data list\n",
    "                    data.append([pair_ab[0],perc])\n",
    "\n",
    "        # Create a new dataframe with data list\n",
    "        abandoned_percentage = pd.DataFrame(data=data).reset_index(drop=True)\n",
    "\n",
    "        # Format the dataframe, and orders data in descending order (shows highest percentage first)\n",
    "        abandoned_percentage.columns = ['Intent','Percentage']\n",
    "        abandoned_percentage.sort_values(ascending=False,inplace=True, by='Percentage')\n",
    "        abandoned_percentage.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Format the data in the percentage column to include '%', and 1 decimal point\n",
    "        abandoned_percentage['Percentage'] = abandoned_percentage['Percentage'].apply(lambda x: \"{0:.1f}%\".format(x))\n",
    "\n",
    "        # Show most abandoned intents\n",
    "        most_abandoned_intents = \"\\nMost abandoned intents (%)\\n\"\n",
    "        print(most_abandoned_intents, \"=\" * len(most_abandoned_intents),'', sep = '')\n",
    "        display(HTML(abandoned_percentage.to_html()))\n",
    "    else:\n",
    "        print('No abandoned intents detected')\n",
    "else:\n",
    "    print('Cannot find \\'response_context_IntentStarted\\' and \\'response_context_IntentCompleted\\' in logs. Please check step 4 and make sure updated logs are reloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate an Excel file that lists all conversations for which there are abandoned and resolved intents for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_intent_abandoned' in locals() and df_intent_abandoned is not None and df_intent_completed is not None:\n",
    "    if len(df_intent_abandoned) == 0:\n",
    "        df_intent_abandoned =  pd.DataFrame(columns = ['Conversation_id','Intent'])\n",
    "    if len(df_intent_completed) == 0:\n",
    "        df_intent_completed =  pd.DataFrame(columns = ['Conversation_id','Intent']) \n",
    "        \n",
    "    # Rename columns\n",
    "    df_intent_abandoned.columns = ['Conversation_id','Intent']\n",
    "    df_intent_completed.columns = ['Conversation_id','Intent']\n",
    "\n",
    "    # Generate excel file\n",
    "    file_name = 'Abandoned_Resolved.xlsx'\n",
    "    generate_excel_measure([df_intent_abandoned,df_intent_completed], ['Abandoned', 'Resolved'], filename= file_name, project_io=None)\n",
    "    link_html = 'Abandoned and resolved intents: <b><a href={} target=\"_blank\">Abandoned_Resolved.xlsx</a></b>'.format(file_name)\n",
    "\n",
    "    display(HTML(link_html))\n",
    "    \n",
    "else:\n",
    "    print('Cannot find \\'response_context_IntentStarted\\' and \\'response_context_IntentCompleted\\' in logs. Please check step 4 and make sure updated logs are reloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 9. Summary and next steps\n",
    "\n",
    "The metrics described above help you narrow your immediate focus of improvement. We suggest the following two strategies: \n",
    "\n",
    "- **Toward improving Effectiveness**\n",
    "\n",
    "    We suggest focusing on a group of problematic conversations, e.g., escalated conversations, then performing a deeper analysis on these conversation as follows. <br>\n",
    "    1. Choose to download either the complete conversations ([All.xlsx](#file_list)), or sampled escalated conversations [Escalated_sample.xlsx](#file_list), or non-escalated conversations [NotEscalated_sample.xlsx](#file_list).<br>\n",
    "    2. Perform a manual assessment of these conversations.<br>\n",
    "    3. Analyze the results using our [Analyze Watson Assistant Effectiveness](https://github.com/watson-developer-cloud/assistant-improve-recommendations-notebook/blob/master/notebook/Effectiveness%20Notebook.ipynb) Jupyter Notebook.\n",
    "\n",
    "\n",
    "- **Toward improving Coverage**\n",
    "\n",
    "    For utterances where an intent was found but no response was given. We suggest performing a deeper analysis to identify  root causes, e.g., missing entities or lacking of dialog logic. \n",
    "\n",
    "    For utterances where no intent was found, we suggest expanding intent coverage as follows.\n",
    "\n",
    "    1. Examine utterances from the production log, especially focus on the utterances that are below the confidence (0.2 by default).\n",
    "    2. If you set a confidence threshold significantly higher than 0.2, we suggest looking at utterances that are below but close to the threshold.\n",
    "    3. Once you select a collection of utterances, intent expansion, you can focus on intent expansion by two methods:\n",
    "        - One-by-One: examine each utterance to either change to an existing intent or add a new intent.\n",
    "        - Unsupervised Learning: perform semantic clustering to generate utterance clusters; examine each cluster to decide (1) adding utterances of an existing intent or (2) creating a new intent.\n",
    "\n",
    "For more information, please check <a href=\"https://github.com/watson-developer-cloud/assistant-improve-recommendations-notebook/raw/master/notebook/IBM%20Watson%20Assistant%20Continuous%20Improvement%20Best%20Practices.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Assistant Continuous Improvement Best Practices</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"authors\"></a>Authors\n",
    "\n",
    "**Zhe Zhang**, Ph.D. in Computer Science, is a Data Scientist for IBM Watson AI. Zhe has a research background in Natural Language Processing, Sentiment Analysis, Text Mining, and Machine Learning. His research has been published at leading  conferences and journals including ACL and EMNLP.\n",
    "\n",
    "**Sherin Varughese** is a Data Scientist for IBM Watson AI. Sherin has her graduate degree in Business Intelligence and Data Analytics and has experience in Data Analysis, Warehousing and Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"acknowledgement\"></a> Acknowledgement\n",
    "\n",
    "The authors would like to thank the following members of the IBM Research and Watson Assistant teams for their contributions and reviews of the notebook:  Matt Arnold, Adam Benvie, Kyle Croutwater, Eric Wayne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
